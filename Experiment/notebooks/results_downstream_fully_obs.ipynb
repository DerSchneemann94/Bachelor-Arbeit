{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessory-identity",
   "metadata": {},
   "source": [
    "# Visualize Results: Downstream Performance - \"Fully Observed\" Experiment\n",
    "\n",
    "This notebook should answer the questions: *Does imputation lead to better downstream performances?*\n",
    "\n",
    "## Notebook Structure \n",
    "\n",
    "* Application Scenario 2 - Downstream Performance  \n",
    "   * Categorical  Columns (Classification)\n",
    "   * Numerical Columns (Regression)\n",
    "   * Heterogenous Columns (Classification and Regression Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broad-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 09:33:07.325752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 09:33:07.413070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 09:33:07.413084: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-08 09:33:07.851331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 09:33:07.851375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 09:33:07.851379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from data_imputation_paper.experiment import read_experiment, read_csv_files\n",
    "from data_imputation_paper.plotting import draw_cat_box_plot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-province",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "median-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context('paper', font_scale=1.5)\n",
    "mpl.rcParams['lines.linewidth'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlimited-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = \"fully_observed_fix\"\n",
    "\n",
    "EXPERIMENT_PATH = Path(f\"../data/experiments/{EXPERIMENT}/\")\n",
    "\n",
    "CLF_METRIC = \"Classification Tasks\"\n",
    "REG_METRIC = \"Regression Tasks\"\n",
    "\n",
    "DOWNSTREAM_RESULT_TYPE = \"downstream_performance_mean\"\n",
    "IMPUTE_RESULT_TYPE = \"impute_performance_mean\"\n",
    "\n",
    "FIGURES_PATH = Path(f\"../paper/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-introduction",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conditional-adaptation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 8 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/Bachelor/teilautomatische-Enkodierung-Code/Experiment/src/data_imputation_paper/experiment.py:184\u001b[0m, in \u001b[0;36mread_experiment\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(columns)):\n\u001b[1;32m    183\u001b[0m     auto_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m auto_columns \u001b[38;5;241m+\u001b[39m columns\n\u001b[1;32m    185\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(auto_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    187\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m objects\n",
      "File \u001b[0;32m~/.conda/envs/Experiment/lib/python3.8/site-packages/pandas/core/generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 5915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   5917\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/Experiment/lib/python3.8/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/Experiment/lib/python3.8/site-packages/pandas/core/generic.py:823\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: AnyArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.conda/envs/Experiment/lib/python3.8/site-packages/pandas/core/internals/managers.py:230\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/.conda/envs/Experiment/lib/python3.8/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 8 elements"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = read_csv_files(read_experiment(EXPERIMENT_PATH), read_details=False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "severe-retreat",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m na_impute_results \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m[\n\u001b[1;32m      2\u001b[0m     (results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m IMPUTE_RESULT_TYPE) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      3\u001b[0m     (results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m na_impute_results\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputed\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m na_impute_results \u001b[38;5;241m=\u001b[39m na_impute_results[na_impute_results\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "na_impute_results = results[\n",
    "    (results[\"result_type\"] == IMPUTE_RESULT_TYPE) & \n",
    "    (results[\"metric\"].isin([\"F1_macro\", \"RMSE\"]))\n",
    "]\n",
    "na_impute_results.drop([\"baseline\", \"corrupted\", \"imputed\"], axis=1, inplace=True)\n",
    "na_impute_results = na_impute_results[na_impute_results.isna().any(axis=1)]\n",
    "na_impute_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "static-treatment",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m downstream_results \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m[\n\u001b[1;32m      2\u001b[0m     (results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m DOWNSTREAM_RESULT_TYPE) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m      3\u001b[0m     (results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# remove experiments where imputation failed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m downstream_results \u001b[38;5;241m=\u001b[39m downstream_results\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m      8\u001b[0m     na_impute_results,\n\u001b[1;32m      9\u001b[0m     how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_fraction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "downstream_results = results[\n",
    "    (results[\"result_type\"] == DOWNSTREAM_RESULT_TYPE) & \n",
    "    (results[\"metric\"].isin([\"F1_macro\", \"RMSE\"]))\n",
    "]\n",
    "\n",
    "# remove experiments where imputation failed\n",
    "downstream_results = downstream_results.merge(\n",
    "    na_impute_results,\n",
    "    how = \"left\",\n",
    "    validate = \"one_to_one\",\n",
    "    indicator = True,\n",
    "    suffixes=(\"\", \"_imp\"),\n",
    "    on = [\"experiment\", \"imputer\", \"task\", \"missing_type\", \"missing_fraction\", \"strategy\", \"column\"]\n",
    ")\n",
    "downstream_results = downstream_results[downstream_results[\"_merge\"]==\"left_only\"]\n",
    "\n",
    "assert len(results[\"strategy\"].unique()) == 1\n",
    "downstream_results.drop([\"experiment\", \"strategy\", \"result_type_imp\", \"metric_imp\", \"train\", \"test\", \"train_imp\", \"test_imp\", \"_merge\"], axis=1, inplace=True)\n",
    "\n",
    "downstream_results = downstream_results.rename(\n",
    "    {\n",
    "        \"imputer\": \"Imputation Method\",\n",
    "        \"task\": \"Task\",\n",
    "        \"missing_type\": \"Missing Type\",\n",
    "        \"missing_fraction\": \"Missing Fraction\",\n",
    "        \"column\": \"Column\",\n",
    "        \"baseline\": \"Baseline\",\n",
    "        \"imputed\": \"Imputed\",\n",
    "        \"corrupted\": \"Corrupted\"\n",
    "    },\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suitable-leonard",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'downstream_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m rename_imputer_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModeImputer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean/Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNNImputer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$k$-NN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGAINImputer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m    \n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m rename_metric_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m: CLF_METRIC,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: REG_METRIC\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m downstream_results \u001b[38;5;241m=\u001b[39m \u001b[43mdownstream_results\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(rename_imputer_dict)\n\u001b[1;32m     16\u001b[0m downstream_results \u001b[38;5;241m=\u001b[39m downstream_results\u001b[38;5;241m.\u001b[39mreplace(rename_metric_dict)\n\u001b[1;32m     18\u001b[0m downstream_results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'downstream_results' is not defined"
     ]
    }
   ],
   "source": [
    "rename_imputer_dict = {\n",
    "    \"ModeImputer\": \"Mean/Mode\",\n",
    "    \"KNNImputer\": \"$k$-NN\",\n",
    "    \"ForestImputer\": \"Random Forest\",\n",
    "    \"AutoKerasImputer\": \"Discriminative DL\",\n",
    "    \"VAEImputer\": \"VAE\",\n",
    "    \"GAINImputer\": \"GAIN\"    \n",
    "}\n",
    "\n",
    "rename_metric_dict = {\n",
    "    \"F1_macro\": CLF_METRIC,\n",
    "    \"RMSE\": REG_METRIC\n",
    "}\n",
    "\n",
    "downstream_results = downstream_results.replace(rename_imputer_dict)\n",
    "downstream_results = downstream_results.replace(rename_metric_dict)\n",
    "\n",
    "downstream_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-acoustic",
   "metadata": {},
   "source": [
    "### Robustness: check which imputers yielded `NaN`values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "choice-williams",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'downstream_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdownstream_results\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      2\u001b[0m     na_sum \u001b[38;5;241m=\u001b[39m downstream_results[col]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m na_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'downstream_results' is not defined"
     ]
    }
   ],
   "source": [
    "for col in downstream_results.columns:\n",
    "    na_sum = downstream_results[col].isna().sum()\n",
    "    if na_sum > 0:\n",
    "        print(\"-----\" * 10)        \n",
    "        print(col, na_sum)\n",
    "        print(\"-----\" * 10)        \n",
    "        na_idx = downstream_results[col].isna()\n",
    "        print(downstream_results.loc[na_idx, \"Imputation Method\"].value_counts(dropna=False))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-terry",
   "metadata": {},
   "source": [
    "## Compute Downstream Performance relative to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "permanent-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_row_idx = downstream_results[\"metric\"] == CLF_METRIC\n",
    "reg_row_idx = downstream_results[\"metric\"] == REG_METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quick-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imputation Method</th>\n",
       "      <th>Task</th>\n",
       "      <th>Missing Type</th>\n",
       "      <th>Missing Fraction</th>\n",
       "      <th>Column</th>\n",
       "      <th>result_type</th>\n",
       "      <th>metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Corrupted</th>\n",
       "      <th>Imputed</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Discriminative DL</td>\n",
       "      <td>40922</td>\n",
       "      <td>MAR</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gyro_y</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.735582</td>\n",
       "      <td>0.735822</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discriminative DL</td>\n",
       "      <td>40922</td>\n",
       "      <td>MAR</td>\n",
       "      <td>0.30</td>\n",
       "      <td>gyro_y</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.725199</td>\n",
       "      <td>0.731309</td>\n",
       "      <td>0.008306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discriminative DL</td>\n",
       "      <td>40922</td>\n",
       "      <td>MAR</td>\n",
       "      <td>0.50</td>\n",
       "      <td>gyro_y</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.732196</td>\n",
       "      <td>0.015513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discriminative DL</td>\n",
       "      <td>40922</td>\n",
       "      <td>MAR</td>\n",
       "      <td>0.10</td>\n",
       "      <td>gyro_y</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.735289</td>\n",
       "      <td>0.735309</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Discriminative DL</td>\n",
       "      <td>40922</td>\n",
       "      <td>MCAR</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gyro_y</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.735530</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>GAIN</td>\n",
       "      <td>1471</td>\n",
       "      <td>MCAR</td>\n",
       "      <td>0.10</td>\n",
       "      <td>V9</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.508405</td>\n",
       "      <td>0.497643</td>\n",
       "      <td>0.515090</td>\n",
       "      <td>0.034317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>GAIN</td>\n",
       "      <td>1471</td>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.01</td>\n",
       "      <td>V9</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.508405</td>\n",
       "      <td>0.506586</td>\n",
       "      <td>0.508398</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>GAIN</td>\n",
       "      <td>1471</td>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.30</td>\n",
       "      <td>V9</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.508405</td>\n",
       "      <td>0.480143</td>\n",
       "      <td>0.530432</td>\n",
       "      <td>0.098914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>GAIN</td>\n",
       "      <td>1471</td>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.50</td>\n",
       "      <td>V9</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.508405</td>\n",
       "      <td>0.451953</td>\n",
       "      <td>0.498481</td>\n",
       "      <td>0.091519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>GAIN</td>\n",
       "      <td>1471</td>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.10</td>\n",
       "      <td>V9</td>\n",
       "      <td>downstream_performance_mean</td>\n",
       "      <td>Classification Tasks</td>\n",
       "      <td>0.508405</td>\n",
       "      <td>0.497431</td>\n",
       "      <td>0.513890</td>\n",
       "      <td>0.032374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4692 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Imputation Method   Task Missing Type  Missing Fraction  Column  \\\n",
       "0     Discriminative DL  40922          MAR              0.01  gyro_y   \n",
       "1     Discriminative DL  40922          MAR              0.30  gyro_y   \n",
       "2     Discriminative DL  40922          MAR              0.50  gyro_y   \n",
       "3     Discriminative DL  40922          MAR              0.10  gyro_y   \n",
       "4     Discriminative DL  40922         MCAR              0.01  gyro_y   \n",
       "...                 ...    ...          ...               ...     ...   \n",
       "4951               GAIN   1471         MCAR              0.10      V9   \n",
       "4952               GAIN   1471         MNAR              0.01      V9   \n",
       "4953               GAIN   1471         MNAR              0.30      V9   \n",
       "4954               GAIN   1471         MNAR              0.50      V9   \n",
       "4955               GAIN   1471         MNAR              0.10      V9   \n",
       "\n",
       "                      result_type                metric  Baseline  Corrupted  \\\n",
       "0     downstream_performance_mean  Classification Tasks  0.735632   0.735582   \n",
       "1     downstream_performance_mean  Classification Tasks  0.735632   0.725199   \n",
       "2     downstream_performance_mean  Classification Tasks  0.735632   0.720784   \n",
       "3     downstream_performance_mean  Classification Tasks  0.735632   0.735289   \n",
       "4     downstream_performance_mean  Classification Tasks  0.735632   0.735530   \n",
       "...                           ...                   ...       ...        ...   \n",
       "4951  downstream_performance_mean  Classification Tasks  0.508405   0.497643   \n",
       "4952  downstream_performance_mean  Classification Tasks  0.508405   0.506586   \n",
       "4953  downstream_performance_mean  Classification Tasks  0.508405   0.480143   \n",
       "4954  downstream_performance_mean  Classification Tasks  0.508405   0.451953   \n",
       "4955  downstream_performance_mean  Classification Tasks  0.508405   0.497431   \n",
       "\n",
       "       Imputed  Improvement  \n",
       "0     0.735822     0.000326  \n",
       "1     0.731309     0.008306  \n",
       "2     0.732196     0.015513  \n",
       "3     0.735309     0.000028  \n",
       "4     0.735632     0.000138  \n",
       "...        ...          ...  \n",
       "4951  0.515090     0.034317  \n",
       "4952  0.508398     0.003565  \n",
       "4953  0.530432     0.098914  \n",
       "4954  0.498481     0.091519  \n",
       "4955  0.513890     0.032374  \n",
       "\n",
       "[4692 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downstream_results[\"Improvement\"]   = (downstream_results[\"Imputed\"] - downstream_results[\"Corrupted\"]  ) / downstream_results[\"Baseline\"]\n",
    "downstream_results.loc[reg_row_idx, \"Improvement\"]   = downstream_results.loc[reg_row_idx, \"Improvement\"]   * -1\n",
    "\n",
    "downstream_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-gnome",
   "metadata": {},
   "source": [
    "## Application Scenario 2 - Downstream Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-bloom",
   "metadata": {},
   "source": [
    "### Categorical  Columns (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "split-chinese",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'downstream_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m draw_cat_box_plot(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdownstream_results\u001b[49m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImprovement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m      5\u001b[0m     FIGURES_PATH,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfully_observed_downstream_boxplot.eps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     hue_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(rename_imputer_dict\u001b[38;5;241m.\u001b[39mvalues()),\n\u001b[1;32m      8\u001b[0m     row_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(rename_metric_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'downstream_results' is not defined"
     ]
    }
   ],
   "source": [
    "draw_cat_box_plot(\n",
    "    downstream_results,\n",
    "    \"Improvement\",\n",
    "    (-0.15, 0.3),\n",
    "    FIGURES_PATH,\n",
    "    \"fully_observed_downstream_boxplot.eps\",\n",
    "    hue_order=list(rename_imputer_dict.values()),\n",
    "    row_order=list(rename_metric_dict.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-baptist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-recycling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
